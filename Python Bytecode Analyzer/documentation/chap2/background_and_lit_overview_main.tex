\chapter{Background \& Literature Overview}

	\section{Python}
		\subsection{History}
		\par Python being a platform-independent \cite[]{srinath2017python}, high-level programming language \cite[pp.2--4]{van1995python}, makes the development of complex software systems a relatively non-trivial task
		in comparison to the production complexity that comes along with other comparable programming languages, such as C \cite[]{summerfield2007rapid}.
		\par The language was developed to be a successor of the ABC programming language \cite[]{geurts1990abc} and initially released as Python V0.9.0 in 
		1991. Similarly to ABC, Python has an English-esque syntax but differs in its application domain; Python being a tool intended for use in a more professional environment, whilst
		ABC is geared towards non-expert computer users \cite[pp.285--288]{van1991interactively}. 
		
		\subsection{Features \& Philosophy}
		\par The simplicity of Python enables it to be an extremely popular language to use in the industry of software development \cite[]{tiobe2022index}. It was designed to be highly readable, 
		thus removing the 'boilerplate' style used in the more traditional languages, such as Pascal. Python uses indentation for block delimiters,
		(off-side rule \cite[pp.4--5]{van2021python}) which is unusual among other popular programming languages \cite[pp.2--3]{van2021python}; new blocks increase in indentation, whilst a decrease in indentation signifies the end of 
		a block. It supports a dynamic type system, enabling the compiler to run faster and the CPython interpreter to dynamically load new code. 
		Dynamic type systems such as Python offer more flexibility; allowing for simpler language syntax, which in turn leads to a smaller source code size \cite[]{dynamic2013typing}. Although dynamically typed,
		Python is also strongly-typed; disallowing operations which are not well-defined. Objects are typed albeit variable names are untyped.

		\par One of Python's most attractive features is that it offers the freedom to allow the developer to use multiple programming paradigms \cite[]{van2007python}; appealing to a wider audience. Python
		also includes a cycle-detecting garbage collector \cite[]{van2007python}, freeing up objects as soon as they become unreachable \cite[pp.9--10]{van1994python}. Objects are not explicitly freed up
		as the collector requires a significant processing overhead \cite[pp.27-30]{zorn1990barrier}, and re-allocating memory to objects every time an object is required is resource consuming. Python has 
		module support in its design philosophy, formulating a highly extensible language. Modules can be written in C/C++ \cite[]{srinath2017python} and imported as libraries in any Python project;
		highlighting the extensibility of the language. There are plenty \footnote{Over 329,000 packages as of September 2021 \cite[]{van2007python}} of readily available 
		third-party libraries suited for many tasks, ranging from Web Development \cite[]{forcier2008python} to complex Machine Learning frameworks \cite[]{pedregosa2011scikit}, further increasing 
		ease-of-use, and supporting the quick and simple development philosophy of Python.

		\subsection{Implementations}
		\par There are several environments which support the Python language, known as implementations. The default, most feature comprehensive Python implementation is 
		CPython \cite[]{vanrossum1995python}; written and maintained by Guido van Rossum. Other popular re-implementations include PyPy \cite[]{bolz2009tracing}, 
		Jython \cite[]{juneau2010definitive} and IronPython \cite[]{mueller2010professional}. This paper will focus on the CPython implementation of the Python language and
		will not cover any of the other alternate implementations.

	\section{CPython}
		\par CPython is the predominant implementation of the Python language written in C. It has a thin compilation layer from source code to CPython bytecode (See \ref{fig:compiler_innards}); simplifying the design of the interpreter.
		Unlike the typically structured program representations, bytecode is easier to parse and has a standardized notation. A comprehensive reference has been compiled for this dissertation, available in Appendix \ref{chap:cpythonvmref}.
		
	
	\section{Analysis}
	\par Program analysis is constituted of four main approaches; \nameref{subsec:cfa}, \nameref{subsec:abstractinterp}, \nameref{subsec:typeeffectsys}, and finally \nameref{subsec:dfa} \cite[pp.1--2]{nielson2004principlesofPA}. Typically, these approaches are practised in conjunction with each other to provide the most accurate approximate answers.
	Program analysis techniques should be semantics-based and not semantics directed; the latter is the process by which the information obtained from the analysis conducted is proved
	to be safe concerning the semantics of the programming language, whilst the former is the process by which the structure of the analysis conducted reflects the structure of the semantics of the language; a process which is 
	not recommended \cite[pp.2--3]{nielson2004principlesofPA}. These approaches also have two main methodologies driving them; Statically analysing a program or Dynamically analysing a program.
	\par Program analysis is conducted before program input, rendering any analysis undecidable. In complexity theory, this is known as Rice's Theorem \cite[]{rice1953classes}. The analysis would need to compute results that are valid for 
	all possible inputs into the program. Seeing as such a statement is near impossible to back up, the aforesaid analysis approximates; producing a \textit{safe} answer \cite[pp.9--11]{andersen1994program}. \textit{Safe} answers are decidedly
	\textit{safe} based upon the aim of the analysis and the information provided to the analysis. A result which might be considered \textit{safe} in a certain analysis, may not be in other analyses.

	
		\subsection{Control Flow Analysis}
		\label{subsec:cfa}
		\par Control Flow analysis (\textit{Constraint Based analysis}) is the act of determining information about what elementary blocks lead to other blocks, whereby seeing the flow of program control. More formally, such an analysis for each 
		function application gives us which functions may be applied. Control Flow analysis makes use of the constraint system. The essence of this method is to extract several inclusions out of a program. This system creates relations which can be 
		constituted from three different classes \cite[pp.10--13]{nielson2004principlesofPA};
		\begin{enumerate}
			\item The relation between the values of the function abstraction and their labels.
			\item The relation between the values of variables and their labels.
			\item The interrelations of application points and their relative function mappings:
				\subitem{Application Point 1}: The constraint representing the formal parameter of the function bounded with the actual parameter value.
				\subitem{Application Point 2}: The constraint representing the value outputted by said function.
		\end{enumerate}
		\par There are multiple types of CFA analyses \cite[pp.139--195]{nielson2004principlesofPA}:
		\begin{itemize}
			\item[-] Abstract 0-CFA Analysis,
			\item[-] Syntax Directed 0-CFA Analysis,
			\item[-] Constrain Based 0-CFA Analysis,
			\item[-] Uniform \textit{k}-CFA Analysis,
		\end{itemize}
		
		\subsection{Dataflow Analysis}
		\label{subsec:dfa}
		\par In Data Flow Analysis, the program is subdivided into sections via elementary blocks, connected by edges, describing the delegation of control in the program.
		There are two primary methodologies of approaching Data Flow analysis; The Equational Approach, and the Constraint Based approach (as mentioned in Section \ref{subsec:cfa})
		\par The equational approach extracts a number of equations from a program; belonging to the following classes:
				
		\begin{itemize}
			\item The relation between the exit information of a node to the entry information of the same node (flow of data).
			\item The relation between the entry information of a node to exit information of nodes from which control could have possibly come from. 
		\end{itemize}
	
		\par There are multiple types of Intra-procedural Data Flow analyses as may be seen below \cite[pp.33--51]{nielson2004principlesofPA}:
		\begin{itemize}
			\item[-] Available Expression Analysis,
			\item[-] Reaching Definition Analysis,
			\item[-] Very Busy Expression Analysis,
			\item[-] Live Variable Analysis.
		\end{itemize}
	
		\par An important form of analysis in this subsection is the Reaching Definition Analysis. It is made use of in other analyses, such as \nameref{subsec:abstractinterp}.
		This type of analysis relates distinct labels to allow the identification of the primitive constructs of a program without the need to construct a flow graph.
	
		\subsection{Abstract Interpretation}
		\label{subsec:abstractinterp}
		\par This form of analysis is the way Analyses are calculated rather than how their specification is constructed. Thus, it is independent of the specification style.
		The analysis maps an initial state and a fixed-point from a concrete domain onto an abstract domain; enabling program properties to be decidable (\ref{fig:eptc_abstraction}). Abstract Interpretation is a three-step procedure \cite[pp.13--17]{nielson2004principlesofPA};
	
			\subsubsection*{Collection of Semantics}
			\par This is the preliminary step which records a set of traces that can possibly reach a program point. A trace records the origins of a variables value.
			From a trace, a set of semantically reaching definitions can be extracted; pairs of variables and labels.
			
			\subsubsection*{Galois Connections}
			\par A Galois connection is the joining of the \textit{trace} sets and a \textit{reaching definition} sets; creating a relation. The construction of this joint set is realized by an abstract function $\alpha$
			and a concretisation function $\gamma$ (seen in Figure \ref{fig:realgaloisconnect}), forming the set ($\alpha$, $\lambda$). The abstraction function extracts reachability information present 
			in a set of traces, whilst the concretisation function produces all traces which are consistent with the given reachability information \cite[pp.14--15]{nielson2004principlesofPA}.
			
			\begin{figure}
				\centering 
				\begin{tikzpicture}
					[    
						longcircle/.style={ellipse, draw=black!100, fill=green!0, very thick, minimum width = 3cm, minimum height = 4.5cm},
						rectanglenode/.style={rectangle, draw=cyan!60, fill=cyan!20, very thick, minimum width=30mm, minimum height = 10mm},
						transparentbox/.style={rectangle,draw=blue!60, fill=blue!0, ultra thick, minimum width = 75mm, minimum height = 40mm},
					]
					
					\node[longcircle] (main) at(0,0) {} ;
					\node[longcircle] (abstract) [right=of main] at(4,0){};
		
					\node [] (texttitleconcrete) [above=of main]{{\bfseries Sets of Traces}};
					\node [] (texttitleabstract) [above=of abstract]{{\bfseries Sets of Reaching Definitions}};
					
		
					\tkzDefPoint(0,1){traces}
					\tkzDefPoint(0,-1){reach}
					
					\tkzDrawPoints[color=black,shape=circle,fill=black,size=3.5](traces)
					\tkzDrawPoints[color=black,shape=circle,fill=black!0,size=3.5](reach)
					
					\tkzDefPoint(6.5,1){traces1}
					\tkzDefPoint(6.5,-1){reach1}
					
					\tkzDrawPoints[color=black,shape=circle,fill=black,size=3.5](reach1)
					\tkzDrawPoints[color=black,shape=circle,fill=black!0,size=3.5](traces1)
					
					\tiny
					\draw[-latex,line width=0.20mm,dashed,dash pattern=on 0.5mm off 0.25mm] (traces.140) to[bend left=(20)] node[above]{Retrieval of Reaching Definitions} (traces1.39);
					\draw[latex-,line width=0.20mm,dashed,dash pattern=on 0.5mm off 0.25mm] (reach.140) to[bend left=(-20)] node[below] {Generation of Traces} (reach1.39);
					\normalsize
		
					\node [] (xtext) [left=of traces] at(0.5,1) {X};
					\node [] (ytext) [left=of reach] at(0.8,-1) {$\gamma$(Y)};
					
					\node [] (xtext1) [right=of traces1] at(5.8,1) {$\alpha$(X)};
					\node [] (ytext1) [right=of reach1] at(6,-1) {Y};
		
		
				\end{tikzpicture}
		
				\caption{Realization of Galois Connection}
				\label{fig:realgaloisconnect}
			\end{figure}
		
		\subsection*{Induced Analysis}
		\par Finally, an induced analysis is performed on the information obtained, providing a calculated analysis of the previously undecidable properties, as shown in
		Figure \ref{fig:eptc_abstraction}. This type of analysis provides a result which is produced efficiently, and relatively precisely.
	
		\begin{figure}
			\centering
			\begin{tikzpicture}
				[
					ellipsenew/.style={ellipse, draw=black!100, fill=green!0, very thick, minimum width = 3cm, minimum height = 4.5cm},
					rectanglenode/.style={rectangle, draw=cyan!60, fill=cyan!20, very thick, minimum width=30mm, minimum height = 10mm},
					transparentbox/.style={rectangle,draw=blue!60, fill=blue!0, ultra thick, minimum width = 75mm, minimum height = 40mm},
				]
	
				\node[ellipsenew] (main) at(0,0) {} ;
				\node[ellipsenew] (abstract) [right=of main] at(4,0){};
				
				%% MAIN ELLIPSE
				\pgfmathsetseed{24122015}
				\begin{scope}
					\tkzDefPoint(0,1){A}
					\tkzDefPoint(0.3,2){B}
					\tkzDefPoint(-0.2,1.3){C}
					\tkzDefPoint(-0.1,1.6){D}
					\tkzDefPoint(1,1.46){E}
					\tkzDefPoint(0.1,1.8){F}
					\tkzDefPoint(0.1,1.8){G}
					\tkzDefPoint(-.4,1.8){H}
					\tkzDefPoint(-0.3,1.5){I}
					\tkzDefPoint(0.5,1.1){J}
					\tkzDefPoint(-0.5,1.1){K}
					\tkzDefPoint(0.5,1.5){L}
					\tkzDefPoint(-0.5,1.5){M}
					\tkzDefPoint(-0.5,1.3){N}
					\tkzDefPoint(-0.7,1.1){O}
					\tkzDefPoint(-0.4,1){P}
					\tkzDefPoint(-0.8,1.2){Q}
					\tkzDefPoint(0.5,-1.5){R}
					\tkzDefPoint(0.3,-1.2){S}
					\tkzDefPoint(0.1,-1.1){T}
					\tkzDefPoint(0.6,-1.2){U}
					\tkzDefPoint(0.1,-0.4){V}
					\tkzDefPoint(0.1,1.3){W}
					\tkzDefPoint(0,-1.5){X}
					\tkzDrawPoints[color=green,shape=circle,fill=green,size=3.5](A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X)
				\end{scope}
							
				\begin{scope}[yshift=-0.5cm]
					\pgfmathsetseed{24122015}
					%\clip(0,0) ellipse (1.5 and 4.5);
					%\clip(0,4) ellipse (1.5 and 4.5);
					\foreach \p in {1,...,50}
					{ 
						\fill[red] (1*rand,1.2*rand) circle (0.06);
					}
					
				\end{scope}
	
				%% ABSTRACT ELLIPSE
	
				\begin{scope}[xshift=6.5cm]
					\tkzDefPoint(0,1){A}
					\tkzDefPoint(0.3,2){B}
					\tkzDefPoint(-0.2,1.3){C}
					\tkzDefPoint(-0.1,1.6){D}
					\tkzDefPoint(1,1.46){E}
					\tkzDefPoint(0.1,1.8){F}
					\tkzDefPoint(0.1,1.8){G}
					\tkzDefPoint(-.4,1.8){H}
					\tkzDefPoint(-0.3,1.5){I}
					\tkzDefPoint(0.5,1.1){J}
					\tkzDefPoint(-0.5,1.1){K}
					\tkzDefPoint(0.5,1.5){L}
					\tkzDefPoint(-0.5,1.5){M}
					\tkzDefPoint(-0.5,1.3){N}
					\tkzDefPoint(-0.7,1.1){O}
					\tkzDefPoint(-0.4,1){P}
					\tkzDefPoint(-0.8,1.2){Q}
					
					\tkzDefPoint(0.5,-1.5){R}
					\tkzDefPoint(0.3,-1.2){S}
					\tkzDefPoint(0.1,-1.1){T}
					\tkzDefPoint(0.6,-1.2){U}
					\tkzDefPoint(0.1,-0.4){V}
					
					\tkzDefPoint(0.1,1.3){W}
					
					\tkzDefPoint(0,-1.5){X}
	
					\tkzDrawPoints[color=green,shape=circle,fill=green,size=3.5](A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X)
					\tkzDrawPoints[color=black,shape=circle,fill=red!30,size=3.5](R,S,T,U,V,X)
				\end{scope}
	
				\begin{scope}[yshift=-0.5cm, xshift=6.5cm]
					\pgfmathsetseed{24122015}
					%\clip(0,0) ellipse (1.5 and 4.5);
					%\clip(0,4) ellipse (1.5 and 4.5);
					\foreach \p in {1,...,50}
					{ 
						\fill[orange!60] (1*rand,1.2*rand) circle (0.06);
					}
					
				\end{scope}
	
				
				\node [] (texttitleconcrete) [above=of main]{{\bfseries Concrete Semantics}};
				\node [] (texttitleabstract) [above=of abstract]{{\bfseries Abstract Semantics}};
	
				\draw[thick] (abstract.140) to[bend left=(-20)] (abstract.39);
				
				%% KEY
				\begin{scope}
					\node[] (key) at(-2,-3.5) {{\bfseries Key:}};
					\node[] (dtrue) [right=of key] at(-2,-3.5) {Definitely True};
					\node[] (dfalse) [right=of key] at(-2,-4.25) {Definitely False};
					\node[] (pfalse) [right=of key] at(-2,-5) {Possibly False};
					\node[] (pfalse) [right=of key] at(-2,-5.75) {False Overapproximation};
	
					\tkzDefPoint(-1.2,-3.5){TESTPOINT_TRUE}
					\tkzDefPoint(-1.2,-4.25){TESTPOINT_FALSE}
					\tkzDefPoint(-1.2,-5){TESTPOINT_POSFALSE}
					\tkzDefPoint(-1.2,-5.75){TESTPOINT_FALSENEGATIVE}
					\tkzDrawPoints[color=green,shape=circle,fill=green,size=3.5](TESTPOINT_TRUE)
					\tkzDrawPoints[color=red,shape=circle,fill=red,size=3.5](TESTPOINT_FALSE)
					\tkzDrawPoints[color=orange!30,shape=circle,fill=orange!30,size=3.5](TESTPOINT_POSFALSE)
					\tkzDrawPoints[color=black,shape=circle,fill=red!30,size=3.5](TESTPOINT_FALSENEGATIVE)
	
				\end{scope}
				
			\end{tikzpicture}
			\caption{Efficiency-Precision trade-off presented by Abstraction Interpretation}
			\label{fig:eptc_abstraction}
		\end{figure}
	
		\pagebreak
		\subsection{Type and Effect Systems}
		\label{subsec:typeeffectsys}
		\par Type and effect systems are the amalgamation of both an Effect System and an Annotated Type System \cite[pp.17--18]{nielson2004principlesofPA}.
		In an Effect System information about what happens when an execution occurs, rendering a change the current state, is produced (ex: what exception might be raised if this execution occurs).
		In an Annotated Type system the judgements that occur describe certain properties of states, such as a variables signum. Further detail into this method of analysis will not be delved into,
		as it is out of this papers scope. A simple Type and Effect listing may be seen in Listing \ref{lst:smlcodesnippet}.
		
		\begin{tikzpicture}[remember picture]
			\node(code) [anatomy] at (0,0){
				\begin{lstlisting}[caption=Type \& Effect System example on SML Code Snippet, language=ML,label=lst:smlcodesnippet]
					!*\mtPoint{mostLeft}*!let val !*\cPart{localVar1}{ref}*! = !*\cPart{localVar2}{reference (fn x=>x)}*!
					in {!*\cPart{localVar3}{ref}*! := (fn n=>n+1);                    
						!ref true    
						}
					end !*\mbPoint{mostBottom}*!
				\end{lstlisting}
			};

			\codeAnnotation{varText1} (3,5) {TYPE: int$\rightarrow$int reference}
			\codeAnnotation{effecttext} (9,5) {EFFECT: creates an int$\rightarrow$int reference}
			\codeAnnotation{text3} (7,2.5) {int$\rightarrow$int reference}

			\draw[->,annotation](varText1) -- (localVar1);
			\draw[->,annotation](effecttext) -- (localVar2);
			\draw[->,annotation](text3) -- (localVar3);

		\end{tikzpicture}