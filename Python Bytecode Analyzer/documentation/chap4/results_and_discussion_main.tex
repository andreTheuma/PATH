\chapter{Evaluation}
    In this chapter \acs{PATH} is tested and evaluated. For testing, programs with varying complexity are used; simple programs ranging to more complex programs. 
    There are three primary \nameref{sec:researchque}, which will be tested in Sections \ref{sec:ffa}, \ref{sec:ins} and \ref{sec:scalex}; validating \acs{PATH}.

    \section{Research Questions}
    \label{sec:researchque}
        The research questions below systematically investigate the need and use of \acs{PATH}. These questions are delved into more depth in Sections \ref{sec:ffa}, \ref{sec:ins}, and \ref{sec:scalex}.
        
        \begin{description}
            \item[RQ 1: How is further analyses facilitated?] \acs{PATH} creates \textit{.facts} files. Such files contain metrics pertaining to the function analysed that are of interest to end users.
            These files' contents are tabulated in \nameref{table:facts_table}.
            \item[RQ 2: What findings are concluded from this project?] Throughout this project, several undocumented findings have been concluded from results generated by \acs{PATH} processing the functions in \textit{project/tests}.
                The primary undocumented findings are listed below:
                \begin{itemize}
                    \item Elementary Blocks in CPython retain their content on the frame stacks, propagating through the blocks.
                    \item \lstinline|LOAD_GLOBAL| is reserved for storing function names.
                    \item Bytecode operations on the frame stack. 
                    \item CPython blocks are not elementary blocks.
                \end{itemize}
                These findings amongst others are further discussed in Section \ref{sec:ins}.
            
            \item[RQ 3: Is \acs{PATH} scalable?] For \acs{PATH} to be of any practical use, it must be able to scale appropriately, and traverse through different function calls.  
            This is possible as it follows a recursive methodology when dealing with \lstinline|MAKE_FUNCTION| calls, and also scales linearly in relation to the number of bytecodes in a function.

        \end{description}

    \section{Facilitating further analyses}
    \label{sec:ffa}
    \par Program analysis is a computationally intensive and time-consuming process. This process is facilitated by the use of automated tools, such as \acs{PATH}. The \textit{facts} generated 
    by \acs{PATH} are thought out in such a way so as to analyse functions and to enable any further analyses, such as carrying out a Data Flow Analysis with the 
    information generated by \acs{PATH}. For a Data Flow Analysis one requires a \acs{CFG} (generated as mentioned in Section \ref{sec:cfimp}), and data-flow equations for every node of the \acs{CFG}.
    A popular approach to Data Flow Analysis is the Reaching Definitions Method (See section \ref{subsec:dfa}). This would be facilitated with \acs{PATH} via the \acs{CFG} generated and the following \textit{.facts} files:
    \textit{StatementUsesLocal.facts} and \textit{PushValue.facts} (refer to \nameref{table:facts_table}); demonstrating that it does indeed reduce the engineering complexity of further analysis. 
    \par This tool enables teams to focus on the analysis itself, negating the preliminary step for the creation of different intermediary representations which analysis is conducted on. The lack of professionals in this area makes complex analysis tools expensive and rare to come across.
        \subsection{Relating \acs{PATH} with current frameworks}
            \par In reality, program analysis cannot be simply bisected into two categories; it is more accurately depicted by the scope shown in Figure \ref{fig:spectrumPA}

            \begin{figure}
                \centering
                \begin{tikzpicture}
                    
                    \node[align=center] (staticstring) at(-6,0){ \bfseries{Static}};
                    \node[align=center] (Dynamicstring) at(6,0){ \bfseries{Dynamic}};
                    \node[align=center] (autostring) at(0,5){ \bfseries{Automated Analysis}};
                    \node[align=center] (manual) at(0,-5){ \bfseries{Manual Analysis}};

                    %%axis
                    \draw[very thick,latex-latex] (-4.4, 0) -- (4.4, 0);
                    \draw[very thick,latex-latex] (0, -4.4) -- (0, 4.4);
                    
                    %%background
                    \draw[ultra thin, gray, step=.5cm] (-4.3,-4.3) grid (4.3,4.3);

                    \tkzDefPoint(-3.9,0){static}
                    \tkzDefPoint(0,4){symEx}
                    \tkzDefPoint(-3.6,-4){manual}
                    \tkzDefPoint(3.4,2){dynamic}
                    \tkzDefPoint(3.6,-4){debug}
                    \tkzDrawPoints[color=black,shape=circle,fill=black!70,size=8](static,symEx,manual,dynamic,debug);
                    
                    \tiny
                    \node[] (text1)[right=of static] at (-5,0.25) {Static Analysis};
                    \node[] (text2)[right=of static] at (-0.5,3.8) {Symbolic Execution};
                    \node[] (text3)[below=of static] at (-3.1,-2.45) {Manual Auditing};
                    \node[] (text4)[below=of debug] at (4,-2.45) {Debugging};
                    \node[] (text4)[above=of dynamic] at (4,1.1) {Fuzzing};

                    \normalsize

                \end{tikzpicture}
                \caption{Scope of Program Analysis}
                \label{fig:spectrumPA}
            \end{figure}
            \subsubsection*{Similar Frameworks}
            \par \acs{PATH} is a pure basic program analysis framework, in which its stereobate lies with the generation of an \acs{IR}. This framework takes inspiration from several other
            Static frameworks which operate similarly:
            \begin{description}
                \item[doop]A Java pointer and Taint Analysis framework that conducts analysis by the SoufflÃ© Datalog Engine \cite[]{bravenboer2009strictly}.
                \item[soot]A Java optimization framework, providing analyses ranging from \acs{CFG} construction to Taint analysis \cite[]{vallee2010soot}.
                \item[Gigahorse]An Ethereum analysis framework, specializing in the decompilation of smart contracts \cite[]{grech2019gigahorse}.
                \item[Vandal]A fast and robust security analysis framework for Ethereum smart contracts \cite[]{brent2018vandal}.
            \end{description}
            \par The frameworks mentioned above are {\bfseries pure} program analysis frameworks (Static Analysis), whereby the analysis is conducted on an \acs{IR}.
            
            \subsubsection*{Alternative Frameworks}
            \par As seen in Figure \ref{fig:spectrumPA}, there are different methods by which program analysis can be conducted. A popular alternative to the Static Analysis Methodology is the Symbolic Execution method.
            Symbolic Execution is a technique for automatic software validation and verification; differing from Static analysis in the way that it does not form an opinion about the accuracy of the approximation generated. It is simply used to show an expected symbolic result about a computation.
            \begin{description}
                \item[Mythril] A security analysis tool for Ethereum smart contracts, following a symbolic execution methodology \cite[]{di2019survey}.
                \item[Manticore] A symbolic execution tool to analyse binaries and Etherum smart contracts \cite[]{mossberg2019manticore}. 
                \item[angr] A platform-agnostic binary analysis framework making use of a symbolic execution engine \cite[]{wang2017angr}.
                \item[Pex] A .NET white box test generation framework using a dynamic symbolic execution engine \cite[]{tillmann2008pex}.
            \end{description}


    \section{Insights}
    \label{sec:ins}
    \par This section collects the undocumented insights that have been noted from the results generated by \acs{PATH} alongside the extensive study into CPython itself.  
        \subsection{Elementary Block Behaviour}
        
        \par In CPython, an elementary block differs from a block. This is not clear in the documentation provided as one might assume that an elementary block in \acs{PA} terms is interchangeable with a CPython block. CPython considers a section of code to be a block if it is encapsulated within the following code-blocks:
        \begin{itemize}
            \item \lstinline|try| block.
            \item \lstinline|with| block.
            \item \lstinline|except| block.
            \item \lstinline|else| block.
            \item \lstinline|finally| block.
        \end{itemize}

        \par The start of a CPython block is indicated by a \lstinline|SETUP_FINALLY| instruction. The end of a CPython block, is indicated with the \lstinline|POP_BLOCK| instruction whereby all elements of the block are popped along with the block itself, shown in Listing \ref{lst:setupfinallyscript} and \ref{lst:setupfinallydis}.

        \begin{lstlisting}[float,language=Python,caption= \lstinline|try...except| script,label=lst:setupfinallyscript]
def test():
    try:
        print("Hello")
    except Exception:
        print("This is an exception")
        \end{lstlisting}

        \begin{lstlisting}[float,language=bash,caption= Excerpt Bytecode Dissasmbly of Listing \ref{lst:setupfinallyscript},label=lst:setupfinallydis,numbers=none]
            6           0 SETUP_FINALLY            7 (to 16)

            7           2 LOAD_GLOBAL              0 (print)
                        ...
                        8 POP_TOP
                       10 POP_BLOCK
                       12 LOAD_CONST               0 (None)
                       14 RETURN_VALUE
            8     >>   16 DUP_TOP
                        ...
            9          28 LOAD_GLOBAL              0 (print)
                        ...
                       40 RETURN_VALUE
            8     >>   42 RERAISE                  0
        \end{lstlisting}

        \subsection{\lstinline|LOAD_GLOBAL| versus \lstinline|LOAD_NAME|}
        \par From the results generated, it was noted that the \lstinline|LOAD_GLOBAL| instruction was used solely to look-up function names, as they cannot be local variables. Typically, the compiler compiles source code with \lstinline|LOAD_NAME| unless the variable stored is implicitly a global variable (such as a function name), or defined explicitly, as shown in Listing \ref{lst:loadglobscript}
        
        \begin{lstlisting}[float,language=Python,caption= \lstinline|LOAD_GLOBAL| script,label=lst:loadglobscript]
def foo():
    global a
    a=3
        \end{lstlisting}

        \begin{lstlisting}[float,language=bash,caption= Bytecode Dissasmbly of Listing \ref{lst:loadglobscript},numbers=none]
            3           0 LOAD_CONST               1 (3)
                        2 STORE_GLOBAL             0 (a)
                        4 LOAD_CONST               0 (None)
                        6 RETURN_VALUE
        \end{lstlisting}
    
        \subsection{Bytecode Operations}
        \par One of the most important findings that has come from the creation of \acs{PATH} is the clear, concise \nameref{table:opcode_table}. Official documentation provided by Python does not explicitly tabulate the operations on the stack performed by each instruction. CPython source code was inspected (namely \textit{ceval.c}), taking note of \lstinline|PUSH()/STACK_GROW()| and \lstinline|POP()/SHRINK()| which both grow the value stack and shrink the value stack, respectively.
        \par The creation of the \nameref{table:opcode_table} has allowed for an accurate dictionary driven implementation of the opcodes and their respective effect on the value stack in \acs{PATH}.
        
    \section{Scalability \& Experimental Results}
    \label{sec:scalex}
    
    \par Individual opcode features of \acs{PATH} were verified with basic functions found in \textit{project/tests/opcode}, logical functionality of \acs{PATH} (such as \acs{CFG} generation) was verified with 
    functions found in \textit{project/tests/logic}, and finally, general purpose testing was conducted via open source programs\footnote{obtained from \url{https://github.com/OmkarPathak/Python-Programs/tree/master/Programs}}.

    \tiny
    \begin{longtable}{|p{5cm}|p{3.5cm}|p{1cm}|p{3cm}|}
        \caption{\acs{PATH} Performance Results}
        \label{table:resultsPATH}
        \endfirsthead
        \endhead
        \hline
        \multicolumn{4}{|c|}{{\bfseries Performance Results}} \\
        \hline
        File Name::main() & Execution Time(ms) & Lines &Bytecode Length\\
        \hhline{|====|}
        P01\_hello.py & 0.34 & 1  & 10\\
        \hline
        P02\_VariableScope.py & 0.74 & 3 & 26\\
        \hline
        P03\_ListsOperations.py & 5.75 & 20 & 238\\
        \hline
        P04\_Factorial.py & 1.3 & 6 & 50\\
        \hline
        P05\_Pattern.py & 4.1 & 11 & 156\\
        \hline
        P06\_CharCount.py & 1.62 & 9 & 64\\
        \hline        
        P07\_PrimeNumber.py & 2.62 & 13 & 104\\
        \hline
        P08\_Fibonacci.py & 0.98 & 4 & 34\\ 
        \hline
        P09\_Factorial & 0.97 & 4 & 34\\
        \hline
        P10\_LCM.py & 1.69 & 8 & 58\\
        \hline
        P11\_BinaryToDecimal.py& 2.20 & 8 & 90\\
        \hline
        P12\_DecimalToBinary.py& 1.04 & 3 & 38\\
        \hline
        P13\_Palindrome.py& 1.17 & 5 & 44\\
        \hline
        P14\_CheckGreater.py& 1.31 & 6 & 50\\
        \hline
        P15\_Arguments.py& FAILED & 6 & 82\\ 
        \hline
        P16\_CountVowels.py& 1.18 & 6 & 40\\
        \hline
        P17\_EvenOdd.py& 1.65 & 8 &62\\
        \hline
        P18\_Logging.py& 1.57 & 9 & 62\\
        \hline
        P19\_SimpleStopWatch.py& 2.41 & 11 & 96\\
        \hline
        P20\_OsModule.py& 2.30 & 6 & 92\\
        \hline
        P21\_GuessTheNumber.py& 2.21 & 11 & 90\\
        \hline
        P22\_SequentialSearch.py& 1.68 & 8 & 66\\
        \hline
        P23\_BinarySearch.py& 2.83 & 14 & 104\\
        \hline
        P24\_SelectionSort.py& 2.73 & 7 & 106\\
        \hline
        P25\_BubbleSort.py& 2.71 & 4 & 100\\
        \hline
        P26\_InsertionSort.py& 2.76 & 8 & 114\\
        \hline
        P27\_MergeSort.py& 1.96 & 7 & 80\\
        \hline
        P28\_QuickSort.py& 1.42 & 6 & 54\\
        \hline
        P29\_ArgumentParser.py& 1.49 & 7 & 60\\
        \hline
        P30\_Array.py& 3.56 & 10 & 148\\
        \hline
        P31\_SinglyLinkedList.py& 3.46 & 13 & 142\\
        \hline
        P32\_Multithreading\_Client.py& 3.58 & 14 & 154\\
        \hline
        P33\_DoublyLinkedList.py& 1.97 & 7 & 80\\
        \hline
        P34\_Stack.py& 2.74 & 9 & 112\\
        \hline
        P35\_NarySearch.py& 11.25 & 40 & 422\\
        \hline
        P36\_SimpleReaderWriter.py& 2.34 & 8 & 96\\
        \hline
        P37\_HangmanGame.py&9.23 & 47& 372\\
        \hline
        P38\_HashingFile.py& 2.99 & 9 & 126\\
        \hline
        P39\_Queue.py&1.58& 7 & 64\\
        \hline
        P40\_ChiperText.py& 1.99 & 7 & 80\\
        \hline
        P41\_PortScanner.py& 1.02 & 3& 38\\
        \hline
        P42\_MultiprocessingPipes.py&2.31& 7& 96\\
        \hline
        P43\_BinarySearchTree.py&4.14 & 15&158\\
        \hline
        P44\_Closures.py& 0.89 & 5 & 10\\
        \hline
        P45\_MoreOnClosures.py&1.85 & 8 & 74\\
        \hline
        P46\_Decorators.py&1.07& 4 & 36\\
        \hline
        P47\_MoreOnDecorators.py&1.21&4&38\\
        \hline
        P48\_CountingSort.py&3.35&13&140\\
        \hline
        P49\_RockPaperScissors.py&11.39&35&434\\
        \hline
        P50\_ListComprehensions.py&10.32&36&378\\
        \hline
        P51\_PythonJSON.py&FAILED&6&62\\
        \hline
        P52\_BucketSort.py&7.54& 21&286\\
        \hline
        P53\_ShellSort.py&4.06& 11&150\\
        \hline
        P54\_PythonCSV.py&FAILED& 4 & 38\\
        \hline
        P55\_Isogram.py&1.61& 7&56\\
        \hline
        P56\_Panagram.py&2.21& 14&86\\
        \hline
        P57\_Anagram.py&1.68& 6 &66\\
        \hline
        P58\_PerfectNumber.py&1.19&5&46\\
        \hline
        P59\_PascalTriangle.py&0.93&4&34\\
        \hline
        P60\_PickleModule.py&2.33&8&80\\
        \hline
    \end{longtable}
    \normalsize

    
    \par Performance results covering all test functions can be found in Table \ref{table:resultsPATH}. The table shows that \acs{PATH} scales with Equation \ref{eq:PAThperf} as shown in Figure \ref{fig:bytecodevstimeperf}.
    \begin{equation}
        \label{eq:PAThperf} 
        Time Taken To Analyse [ms] = 0.02592 (No. of Bytecodes) + 0.05145 
    \end{equation}
    Throughout testing, results show that \acs{PATH} has 95\% success-rate of analysis from over 60 functions, which is a satisfactory result.

    %%DATA TABLE
    \pgfplotstableread{
            X Y
            10 0.335216522216796875
            26 0.741720199584960937
            34 0.9319782257080078125
            34 0.9701251983642578125
            34 0.975131988525390625
            36 1.0659694671630859375
            38 1.0201930999755859375
            38 1.039981842041015625
            38 1.209259033203125
            40 1.183032989501953125
            44 1.1718273162841796875
            46 1.186847686767578125
            50 1.2981891632080078125
            50 1.3091564178466796875
            54 1.4169216156005859375
            56 1.613140106201171875
            58 1.6882419586181640625
            60 1.4898777008056640625
            62 1.64508819580078125
            62 1.5738010406494140625
            64 1.576900482177734375
            64 1.62410736083984375
            66 1.6813278198242187
            66 1.6841888427734375
            74 1.8520355224609375
            80 1.964092254638671875
            80 1.9738674163818359375
            80 1.99985504150390625
            80 2.3300647735595703125
            86 2.216815948486328125
            90 2.2099018096923828125
            90 2.20203399658203125
            96 2.3109912872314453125
            96 2.3391246795654296875
            96 2.4058818817138671875
            100 2.7101039886474609375
            104 2.6209354400634765625
            104 2.8259754180908203125
            106 2.7258396148681640625
            112 2.7410984039306640625
            114 2.7630329132080078125
            126 2.995014190673828125
            140 3.3528804779052734375
            142 3.464221954345703125
            148 3.5598278045654296875
            150 4.0581226348876953125
            154 3.5762786865234375
            156 4.096031188964844
            158 4.1401386260986328125
            238 5.7508945465087890625
            286 7.5418949127197265625
            372 9.2289447784423828125
            378 10.3168487548828125
            422 11.24811172485351565
            434 11.388063430786132813
            }\datatable

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}
        \begin{axis}[
            title={Number of bytecodes versus time taken for analysis},
            xlabel={Bytecodes},
            ylabel={Time [ms]},
            xmin=0, xmax=500,
            ymin=0, ymax=14,
            x=0.025cm,
            y=0.8cm,
            xtick={0,50,100,150,200,250,300,350,400,450,500},
            ytick={0,1,2,3,4,5,6,7,8,9,10,11,12,13,14},
            legend pos=north west,
            ymajorgrids=true,
            grid style=dashed,
        ]


            \addplot [only marks, mark = *] table{\datatable};
            
            \addplot [thick, red] table[
                y={create col/linear regression={y=Y}}
            ]
            {\datatable};
        
        \end{axis}
        \end{tikzpicture}
        \caption{\acs{PATH} performance}
        \label{fig:bytecodevstimeperf}
    \end{figure}

    \par As functions increase in size, Manual Auditing becomes an incomprehensibly complicated and time-consuming task. \acs{PATH} automates this process in a resource and time-efficient way. Performance results are shown in table \ref{table:resultsPATH}. \acs{PATH} does not enter function calls, but represents them in a shorthand notation as shown in Listing \ref{lst:funccalldemo}. Function calls are saved in \textit{resources/FunctionsNotAnalysed.facts}, as functions that are referenced by the function analysed. Functions that are referenced from the Python Standard Library (\textit{stdlib/builtins.pyi}) are excluded, as analysis of user functions is of interest.

    \begin{lstlisting}[language=bash,caption=Boilerplate of \textit{resources/FunctionsNotAnalysed.facts},numbers=none,label=lst:funccalldemo]
                <filepath>  <function_not_analysed>
    \end{lstlisting}

    \par The time complexity of an Analysis Tool directly affects the adoption of the tool. A lower time complexity is prioritized over accuracy. This is shown in the industry with Andersen's Points-To Analysis and Steensgaard's Points-To Analysis. Andersen's has an average time complexity of   
    $\mathcal{O}(n^c)$ in comparison to Steensgaard's $\mathcal{O}(n)$. Even though Andersen's Points-To Analysis is more accurate than Steengaard's, the latter has been adopted by the industry.
    \par Similarly, \acs{PATH} scales linearly in relation to the amount of bytecodes in a function (refer to Figure \ref{fig:bytecodevstimeperf}). $\mathcal{O}(n)$ time complexity gives \acs{PATH} the potential to be widely adopted, as was Steensgaard's Analysis. 
    
    
    \subsection{Case Study}
        \par To further demonstrate the scaleability of \acs{PATH}, a Case Study on a simple program shall be conducted. An address book application \textit{project/tests/samplePrograms/P61\_AddressBook.py} that performs storing, searching and deletion of records, is tested out in this subsection.

        \begin{description}
            \item[Initial Analysis] \lstinline|main()| is the first function analysed, as it is the entry point of the address book. From this initial analysis we see that the class \lstinline|AddressBook()| is initialized from the main function, from \textit{resources/FunctionsNotAnalysed.facts} (Listing \ref{lst:funcnotana}). Thus, all functions that lie in the \lstinline|AddressBook()| class need to be analysed.
            \item[Subsequent Analyses] The functions pertaining to the \lstinline|AddressBook()| class are then analysed; \lstinline|addContacts()|, \lstinline|getDetailsFromUser()|, \lstinline|displayContacts()|, \lstinline|searchContacts()| and \lstinline|modifyContacts()|. All these results are tabulated in Table \ref{table:casestudy}
            \small
            \begin{lstlisting}[float=h,language=bash,caption= \textit{resources/FunctionsNotAnalysed.facts},label=lst:funcnotana,numbers=none]
Python Bytecode Analyzer/project/tests/samplePrograms/P61_AddressBook.py	AddressBook.addContacts()
Python Bytecode Analyzer/project/tests/samplePrograms/P61_AddressBook.py	AddressBook.getDetailsFromUser()
Python Bytecode Analyzer/project/tests/samplePrograms/P61_AddressBook.py	AddressBook.displayContacts()
Python Bytecode Analyzer/project/tests/samplePrograms/P61_AddressBook.py	AddressBook.searchContacts()
Python Bytecode Analyzer/project/tests/samplePrograms/P61_AddressBook.py	AddressBook.modifyContacts()
            \end{lstlisting}

            \begin{lstlisting}[float,language=bash,caption= \textit{resources/SimpleIR.facts},label=lst:funcIR,numbers=none]
Vd8b5        CALL_FUNCTION   AddressBook     NO ARGS
Va7fd        LOAD_METHOD     addContacts     NO ARGS
V0a7e        LOAD_METHOD     searchContacts  NO ARGS
Vfadc        LOAD_METHOD     modifyContacts  NO ARGS
Vfa7f        LOAD_METHOD     displayContacts NO ARGS   

            \end{lstlisting}
            
            \begin{table}[ht]
                \centering
                \begin{tabular}{|p{4.7cm}|p{3.3cm}|p{4cm}|}
                    \hline
                    \multicolumn{3}{|c|}{{\bfseries Address Book }} \\
                    \hline
                    Function & Execution Time(ms) & Bytecode Length \\
                    \hhline{|===|}
                    \lstinline|main()| & 3.09 & 124\\
                    \hline
                    \lstinline|AddressBook::addContacts()| & 5.1 & 200 \\
                    \hline
                    \lstinline|AddressBook::getDetailsFromUser()| & 2.83 & 108\\
                    \hline
                    \lstinline|AddressBook::displayContacts()| & 2.82 & 110\\
                    \hline
                    \lstinline|AddressBook::searchContacts()| & 5.17 & 186\\
                    \hline
                    \lstinline|AddressBook::modifyContacts()| & 11.05 & 452\\
                    \hhline{|===|}
                    \multicolumn{3}{|c|}{{\bfseries Totals }} \\
                    \hhline{|===|}
                    & 30.4 & 1180 \\
                    \hline
                \end{tabular}
                \caption{Address Book case study}
                \label{table:casestudy}
            \end{table}
            \normalsize
            \par For verification, the result produced by the \acs{PATH} Equation \ref{eq:PAThperf} is 30.64 ms. This result is within the margin of error (error of 0.76\%) for timing functions, considering rounding.

        \end{description}